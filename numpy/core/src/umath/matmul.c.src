/* -*- c -*- */

#define _UMATHMODULE
#define _MULTIARRAYMODULE
#define NPY_NO_DEPRECATED_API NPY_API_VERSION

#include "Python.h"

#include "npy_config.h"
#include "numpy/npy_common.h"
#include "numpy/arrayobject.h"
#include "numpy/ufuncobject.h"
#include "numpy/npy_math.h"
#include "numpy/halffloat.h"
#include "lowlevel_strided_loops.h"

#include "npy_pycompat.h"

#include "npy_cblas.h"
#include "arraytypes.h" /* For TYPE_dot functions */
#include <assert.h>

/*
 *****************************************************************************
 **                            BASICS                                       **
 *****************************************************************************
 */

#if defined(HAVE_CBLAS)
static const npy_cdouble oneD = {1.0, 0.0}, zeroD = {0.0, 0.0};
static const npy_cfloat  oneF = {1.0, 0.0}, zeroF = {0.0, 0.0};

/**begin repeat
 *
 * #name = FLOAT, DOUBLE, CFLOAT, CDOUBLE#
 * #ctype = npy_float, npy_double, npy_cfloat, npy_cdouble#
 * #type = npy_float, npy_double, npy_cfloat, npy_cdouble#
 * #prefix = s, d, c, z#
 * #step1 = 1.F, 1., &oneF, &oneD#
 * #step0 = 0.F, 0., &zeroF, &zeroD#
 */
NPY_NO_EXPORT void
@name@_gemv(void *ip1, npy_intp is1_m, void *ip2, npy_intp is2_n, void *op,
               npy_intp m, npy_intp n)
{
    /*
     * Vector matrix multiplication -- Level 2 BLAS
     * arguments
     * ip1: contiguous data, m*n shape
     * ip2: data in c order, n*1 shape
     * op:  contiguous data in c order, m shape
     */
    enum CBLAS_ORDER order;
    int lda;

    if (is1_m == sizeof(@type@)) {
        order = CblasColMajor;
        lda = n;
    }
    else {
        /* If not ColMajor, caller should have ensured we are RowMajor */
        /* will not assert in release mode */
        assert(is1_m == sizeof(@type@) * m);
        order = CblasRowMajor;
        lda = m;
    }
    cblas_@prefix@gemv(order, CblasTrans, n, m, @step1@, ip1, lda, ip2,
                                     is2_n / sizeof(@type@), @step0@, op, 1);
}

NPY_NO_EXPORT void
@name@_matmul_matrixmatrix(void *ip1, npy_intp is1_m, npy_intp is1_n,
                           void *ip2, npy_intp is2_n, npy_intp is2_p,
                           void *op, npy_intp m, npy_intp n, npy_intp p)
{
    /*
     * matrix matrix multiplication -- Level 3 BLAS
     */
    enum CBLAS_ORDER order = CblasRowMajor;
    enum CBLAS_TRANSPOSE trans1, trans2;
    int M, N, P, lda, ldb;
    M = m;
    N = n;
    P = p;

    if (is1_m == sizeof(@type@)) {
        trans1 = CblasTrans;
        lda = N > 1 ? is1_n / sizeof(@type@) : 1;
    }
    else {
        /* If not ColMajor, caller should have ensured we are RowMajor */
        /* will not assert in release mode */
        assert(is1_n == sizeof(@type@));
        trans1 = CblasNoTrans;
        lda = N > 1 ? is1_m / sizeof(@type@) : 1;
    }
    if (is2_n == sizeof(@type@)) {
        trans2 = CblasTrans;
        ldb = N > 1 ? is2_p / sizeof(@type@) : 1;
    }
    else {
        /* If not ColMajor, caller should have ensured we are RowMajor */
        /* will not assert in release mode */
        assert(is2_p == sizeof(@type@));
        trans2 = CblasNoTrans;
        ldb = P > 1 ? P : 1;
    }
    /*
     * Use syrk if we have a case of a matrix times its transpose.
     * Otherwise, use gemm for all other cases.
     */
    if (
        (ip1 == ip2) &&
        (m == p) &&
        (is1_m == is2_p) &&
        (is1_n == is2_n) &&
        (trans1 != trans2)
    ) {
        npy_intp i,j;
        if (trans1 == CblasNoTrans) {
            cblas_@prefix@syrk(order, CblasUpper, trans1, P, N, @step1@,
                               ip1, lda, @step0@, op, P);
        }
        else {
            cblas_@prefix@syrk(order, CblasUpper, trans1, P, N, @step1@,
                               ip1, ldb, @step0@, op, P);
        }
        /* Copy the triangle */
        for (i = 0; i < P; i++) {
            for (j = i + 1; j < P; j++) {
                ((@type@*)op)[j * P + i] = ((@type@*)op)[i * P + j];
            }
        }

    }
    else {
        cblas_@prefix@gemm(order, trans1, trans2, M, P, N, @step1@, ip1, lda,
                           ip2, ldb, @step0@, op, P);
    }
}

/**end repeat**/
#endif

/*
 * matmul loops
 * signature is (m?,n),(n,p?)->(m?,p?)
 */

/**begin repeat
 * #TYPE = FLOAT, DOUBLE, HALF#
 * #typ = npy_float,npy_double,npy_half#
 * #SPECL = 0,0,1#
 */

NPY_NO_EXPORT void
@TYPE@_matmul_inner_noblas(char *ip1, char *ip2, char *op,
                           npy_intp dm, npy_intp dn, npy_intp dp,
                           npy_intp ib1_n, npy_intp ib2_n, npy_intp ib2_p,
                           npy_intp ob_p, npy_intp is1_m, npy_intp is1_n,
                           npy_intp is2_n, npy_intp is2_p, npy_intp os_m,
                           npy_intp os_p)
{
    npy_intp m, n, p;
    for (m = 0; m < dm; m++) {
        for (p = 0; p < dp; p++) {
            /*
             * Use a double as an intermediate sum, which is natural for
             * npy_double, slightly increases the accuracy of npy_float,
             * and is perhaps overkill for npy_half.
             */
            double sum = 0;
            for (n = 0; n < dn; n++) {
#if @SPECL@ == 1
                @typ@ val1 = (*(@typ@ *)ip1);
                @typ@ val2 = (*(@typ@ *)ip2);
                sum += npy_half_to_float(val1) * npy_half_to_float(val2);
#else
                sum += ((double)*(@typ@ *)ip1) * ((double)*(@typ@ *)ip2);
#endif
                ip2 += is2_n;
                ip1 += is1_n;
            }
#if @SPECL@ == 1
            *(@typ@ *)op = npy_float_to_half((float)sum);
#else
            /* in the case of double -> float, may produce INF */
            *(@typ@ *)op = (@typ@)sum;
#endif
            ip1 -= ib1_n;
            ip2 -= ib2_n;
            op  +=  os_p;
            ip2 += is2_p;
        }
        op -= ob_p;
        ip2 -= ib2_p;
        ip1 += is1_m;
        op  +=  os_m;
    }
}

/**end repeat**/

/**begin repeat
 *  #TYPE = LONGDOUBLE,
 *          CFLOAT, CDOUBLE, CLONGDOUBLE,
 *          UBYTE, USHORT, UINT, ULONG, ULONGLONG,
 *          BYTE, SHORT, INT, LONG, LONGLONG,
 *          BOOL#
 *  #typ = npy_longdouble,
 *         npy_cfloat, npy_cdouble, npy_clongdouble,
 *         npy_ubyte, npy_ushort, npy_uint, npy_ulong, npy_ulonglong,
 *         npy_byte, npy_short, npy_int, npy_long, npy_longlong,
 *         npy_bool#
 * #IS_COMPLEX = 0, 1, 1, 1, 0*11#
 */

NPY_NO_EXPORT void
@TYPE@_matmul_inner_noblas(char *ip1, char *ip2, char *op,
                           npy_intp dm, npy_intp dn, npy_intp dp,
                           npy_intp ib1_n, npy_intp ib2_n, npy_intp ib2_p,
                           npy_intp ob_p, npy_intp is1_m, npy_intp is1_n,
                           npy_intp is2_n, npy_intp is2_p, npy_intp os_m,
                           npy_intp os_p)
{
    npy_intp m, n, p;
    for (m = 0; m < dm; m++) {
        for (p = 0; p < dp; p++) {
#if @IS_COMPLEX@ == 1
            (*(@typ@ *)op).real = 0;
            (*(@typ@ *)op).imag = 0;
#else
            *(@typ@ *)op = 0;
#endif
            for (n = 0; n < dn; n++) {
                @typ@ val1 = (*(@typ@ *)ip1);
                @typ@ val2 = (*(@typ@ *)ip2);
#if @IS_COMPLEX@ == 1
                (*(@typ@ *)op).real += (val1.real * val2.real) -
                                       (val1.imag * val2.imag);
                (*(@typ@ *)op).imag += (val1.real * val2.imag) +
                                       (val1.imag * val2.real);
#else
                *(@typ@ *)op += val1 * val2;
#endif
                ip2 += is2_n;
                ip1 += is1_n;
            }
            ip1 -= ib1_n;
            ip2 -= ib2_n;
            op  +=  os_p;
            ip2 += is2_p;
        }
        op -= ob_p;
        ip2 -= ib2_p;
        ip1 += is1_m;
        op  +=  os_m;
    }
}

/**end repeat**/

/**begin repeat
 *  #TYPE = FLOAT, DOUBLE, LONGDOUBLE, HALF,
 *          CFLOAT, CDOUBLE, CLONGDOUBLE,
 *          UBYTE, USHORT, UINT, ULONG, ULONGLONG,
 *          BYTE, SHORT, INT, LONG, LONGLONG,
 *          BOOL#
 *  #typ = npy_float,npy_double,npy_longdouble, npy_half,
 *         npy_cfloat, npy_cdouble, npy_clongdouble,
 *         npy_ubyte, npy_ushort, npy_uint, npy_ulong, npy_ulonglong,
 *         npy_byte, npy_short, npy_int, npy_long, npy_longlong,
 *         npy_bool#
 * #SPECL = 0, 0, 0, 2, 1, 1, 1, 0*11#
 * #USEBLAS = 1, 1, 0, 0, 1, 1, 0*12#
 * #chr = s, d, 0, 0, c, z, 0*12#
 * #blas_typ = npy_float, npy_double, void*16#
 */


NPY_NO_EXPORT void
@TYPE@_matmul(char **args, npy_intp *dimensions, npy_intp *steps, void *NPY_UNUSED(func))
{
    npy_intp dOuter = *dimensions++;
    npy_intp iOuter;
    npy_intp s0 = *steps++;
    npy_intp s1 = *steps++;
    npy_intp s2 = *steps++;
    npy_intp dm = dimensions[0];
    npy_intp dn = dimensions[1];
    npy_intp dp = dimensions[2];
    npy_intp is1_m=steps[0], is1_n=steps[1], is2_n=steps[2], is2_p=steps[3],
         os_m=steps[4], os_p=steps[5];
    npy_intp ib1_n, ib2_n, ib2_p, ob_p;
#if @USEBLAS@ & defined(HAVE_CBLAS)
    npy_bool special_case = (dm == 1 || dn == 1 || dp == 1);
    npy_bool scalar_out = (dm ==1 && dp == 1);
    npy_bool scalar_vec = (dn == 1 && (dp == 1 || dm == 1));
    npy_bool too_big_for_blas = (dm > NPY_MAX_INT || dn > NPY_MAX_INT ||
                                 dp >= NPY_MAX_INT);
    npy_bool input_contiguous = ((is1_m == sizeof(@typ@) ||
                                  is1_n == sizeof(@typ@)) &&
                                 (is2_n == sizeof(@typ@) ||
                                  is2_p == sizeof(@typ@)));
    npy_bool vector_matrix = ((dm == 1) &&
                   (is2_n == sizeof(@typ@) || (is2_n == sizeof(@typ@) * dp)));
    npy_bool matrix_vector = ((dp == 1)  &&
                   (is1_n == sizeof(@typ@) || (is1_n == sizeof(@typ@) * dm)));
#endif

    ib1_n = is1_n*dn;
    ib2_n = is2_n*dn;
    ib2_p = is2_p*dp;
    ob_p  = os_p *dp;

    if (dn == 0) {
        /* No operand, need to zero the output */
        for (iOuter = 0; iOuter < dOuter; iOuter++,
                        args[0] += s0, args[1] += s1, args[2] += s2) {
            npy_intp m, p;
            char *op=args[2];
            for (m = 0; m < dm; m++) {
                for (p = 0; p < dp; p++) {
#if @SPECL@ == 1
                    (*(@typ@ *)op).real = 0;
                    (*(@typ@ *)op).imag = 0;
#else
                    *(@typ@ *)op = 0;
#endif
                    op  +=  os_p;
                }
                op  +=  os_m - ob_p;
            }
        }
        return;
    }
    for (iOuter = 0; iOuter < dOuter; iOuter++,
                         args[0] += s0, args[1] += s1, args[2] += s2) {
        char *ip1=args[0], *ip2=args[1], *op=args[2];
#if @USEBLAS@ & defined(HAVE_CBLAS)
        /*
         * TODO: refactor this out to a inner_loop_selector, in
         * PyUFunc_MatmulLoopSelector. But that call does not have access to
         * n, m, p and strides.
         */
        if (too_big_for_blas) {
            @TYPE@_matmul_inner_noblas(ip1, ip2, op, dm, dn, dp,
                      ib1_n, ib2_n, ib2_p, ob_p,
                      is1_m, is1_n, is2_n, is2_p, os_m, os_p);
        }
        else if (special_case) {
            /* Special case variants that have a 1 in the core dimensions */
            if (scalar_out) {
                /* row @ column, 1,1 output */
                @TYPE@_dot(ip1, is1_n, ip2, is2_n, op, dn, NULL);
            } else if (scalar_vec){
                /*
                 * 0d @ vector or vector @ 0d
                 * could use cblas_Xaxy, but that requires 0ing output
                 * and would not be faster (XXX prove it)
                 */
                @TYPE@_matmul_inner_noblas(ip1, ip2, op, dm, dn, dp,
                          ib1_n, ib2_n, ib2_p, ob_p,
                          is1_m, is1_n, is2_n, is2_p, os_m, os_p);
            } else if (vector_matrix) {
                /* vector @ matrix, switch ip1, ip2, p and m */
                @TYPE@_gemv((void*)ip2, is2_n, (void*)ip1, is1_n,
                            (void*)op, dp, dn);
            } else if  (matrix_vector) {
                /* matrix @ vector */
                @TYPE@_gemv((void*)ip1, is1_n, (void*)ip2, is2_n,
                            (void*)op, dm, dn);
            } else {
                /* column @ row, 2d output, no blas needed or non-contiguous input */
                @TYPE@_matmul_inner_noblas(ip1, ip2, op, dm, dn, dp,
                          ib1_n, ib2_n, ib2_p, ob_p,
                          is1_m, is1_n, is2_n, is2_p, os_m, os_p);
            }
        } else {
            /* matrix @ matrix */
            if (input_contiguous) {
                /* can only use blas if input is contiguous */
                @TYPE@_matmul_matrixmatrix((void*)ip1, is1_m, is1_n,
                                           (void*)ip2, is2_n, is2_p,
                                           (void*)op, dm, dn, dp);
            } else {
                @TYPE@_matmul_inner_noblas(ip1, ip2, op, dm, dn, dp,
                          ib1_n, ib2_n, ib2_p, ob_p,
                          is1_m, is1_n, is2_n, is2_p, os_m, os_p);
            }
        }
#else
        @TYPE@_matmul_inner_noblas(ip1, ip2, op, dm, dn, dp,
                          ib1_n, ib2_n, ib2_p, ob_p,
                          is1_m, is1_n, is2_n, is2_p, os_m, os_p);

#endif
    }
}

/**end repeat**/


